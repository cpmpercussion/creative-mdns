{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing an MDRNN on Human Data\n",
    "\n",
    "This script trains and tests a mixture density recurrent neural network (MDRNN) on a 10-minute human sourced performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import sketch_mdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV and create dt \n",
    "perf_df = pd.DataFrame.from_csv('./data/2018-01-25T14-04-35-rnnbox.csv', parse_dates=True)\n",
    "perf_df['time'] = perf_df.index\n",
    "perf_df['seconds'] = perf_df.index\n",
    "perf_df.time = perf_df.time.diff()\n",
    "perf_df.time = perf_df.time.dt.total_seconds()\n",
    "perf_df = perf_df.dropna()\n",
    "perf_df.value = perf_df.value / 255.0\n",
    "corpus_df = pd.DataFrame({'t': perf_df.time, 'x': perf_df.value})\n",
    "corpus = np.array(corpus_df)\n",
    "print(\"Shape of corpus array:\", corpus.shape)\n",
    "corpus_df.describe()\n",
    "perf_df.seconds = perf_df.seconds - perf_df.seconds[0]\n",
    "perf_df.seconds = perf_df.seconds.dt.total_seconds()\n",
    "perf_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the human performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = perf_df[:5000].plot(x='seconds', y='value', kind=\"line\", figsize=(15,4), legend=False)\n",
    "ax.set_xlabel(\"seconds\")\n",
    "ax.set_ylabel(\"position\")\n",
    "ax.get_figure().savefig('human_data_output.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "ax.get_figure().savefig('human_data_output.png', dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Human Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "units = 128\n",
    "mixes = 8\n",
    "layers = 3\n",
    "batch_s = 100\n",
    "n_steps = 120\n",
    "epochs = 10\n",
    "\n",
    "# Train\n",
    "net = sketch_mdn.MixtureRNN(mode = sketch_mdn.NET_MODE_TRAIN, \n",
    "                            n_hidden_units=units, \n",
    "                            n_mixtures=mixes, \n",
    "                            batch_size=batch_s, \n",
    "                            sequence_length=n_steps, \n",
    "                            layers=layers)\n",
    "loader = sketch_mdn.SequenceDataLoader(num_steps=(n_steps + 1), batch_size=batch_s, corpus=corpus)\n",
    "losses = net.train(loader, epochs, saving=True)\n",
    "## Plot the losses.\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Human Data Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "units = 128\n",
    "mixes = 8\n",
    "layers = 3\n",
    "n_steps = 1\n",
    "batch_s = 1\n",
    "\n",
    "# Instantiate Running Network\n",
    "net = sketch_mdn.MixtureRNN(mode = sketch_mdn.NET_MODE_RUN, \n",
    "                            n_hidden_units=units, \n",
    "                            n_mixtures=mixes, \n",
    "                            batch_size=batch_s, \n",
    "                            sequence_length=n_steps, \n",
    "                            layers=layers)\n",
    "\n",
    "first_touch = np.array([(0.01 + (np.random.rand()-0.5)*0.005), np.random.rand()])\n",
    "print(\"Test Input:\",first_touch)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    perf = net.generate_performance(first_touch,1000,sess)\n",
    "print(\"Test Output:\")\n",
    "perf_df = pd.DataFrame({'t':perf.T[0], 'x':perf.T[1]})\n",
    "perf_df['time'] = perf_df.t.cumsum()\n",
    "#plt.show(perf_df.plot('time','x',kind='scatter'))\n",
    "plt.plot(perf_df.time, perf_df.x, '.r-')\n",
    "plt.show()\n",
    "print(perf_df.describe())\n",
    "\n",
    "# ## Investigate Output\n",
    "# window = 100\n",
    "# for n in [1000,2000,3000,4000,5000,6000]:\n",
    "#     print(\"Window:\", str(n),'to',str(n+window))\n",
    "#     plt.plot(perf_df[n:n+window].time, perf_df[n:n+window].x, '.r-')\n",
    "#     plt.show()\n",
    "\n",
    "# input_touch = first_touch.reshape([1,1,net.n_input_units]) ## Give input correct shape for one-at-a-time evaluation.\n",
    "# if net.state is not None:\n",
    "#     feed = {net.x: input_touch, net.init_state: net.state}\n",
    "# else:\n",
    "#     feed = {net.x: input_touch}\n",
    "# pis, locs_1, locs_2, scales_1, scales_2, corr, net.state = sess.run([net.pis, net.locs_1, net.locs_2, net.scales_1, net.scales_2,  net.corr, net.final_state], feed_dict=feed)\n",
    "# #x_1, x_2 = sketch_mixture.sample_mixture_model(pis, locs_1, locs_2, scales_1, scales_2, corr, temp=1.0, greedy=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
