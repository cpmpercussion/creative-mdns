{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing an MDRNN on Synthetic Data\n",
    "\n",
    "This script trains and tests a mixture density recurrent neural network (MDRNN) on synthetic performances.\n",
    "\n",
    "Ideas to investigate:\n",
    "\n",
    "- give the data a variety of periods instead of 15000 samples in the same\n",
    "- save all the waves together (done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "## Parameters for time distribution (found from studying human sourced data)\n",
    "time_mean = 0.044860\n",
    "time_std = 0.183995\n",
    "time_min = 0.000454\n",
    "time_max = 8.463944\n",
    "\n",
    "def gen_function_data(function_generator, freq, num_samples):\n",
    "    \"\"\"Generates data using a generator function.\"\"\"\n",
    "    t_diffs = np.random.normal(loc=time_mean, scale=time_std, size=num_samples)\n",
    "    out_df = pd.DataFrame({'dt' : t_diffs})\n",
    "    out_df.dt = out_df.dt.abs()\n",
    "    out_df['seconds'] = out_df.dt.cumsum()\n",
    "    out_df['value'] = (function_generator(freq * 2 * np.pi * out_df.seconds) * 0.5) + 0.5\n",
    "    return out_df\n",
    "\n",
    "def gen_noise(num_samples):\n",
    "    t_diffs = np.random.normal(loc=time_mean, scale=time_std, size=num_samples)\n",
    "    values = np.random.uniform(low=0.0, high=1.0, size=num_samples)\n",
    "    out_df = pd.DataFrame({'dt' : t_diffs, 'value' : values})\n",
    "    out_df.dt = out_df.dt.abs()\n",
    "    out_df['seconds'] = out_df.dt.cumsum()\n",
    "    return out_df\n",
    "\n",
    "NSAMPLE = 150000\n",
    "# Generate Synthetic data from different functions with different frequencies.\n",
    "output_dfs = []\n",
    "functions = [np.sin, scipy.signal.square, (lambda t: scipy.signal.sawtooth(t, width=0.5))]\n",
    "frequencies = [0.1, 0.35, 0.6, 0.85, 1.1]\n",
    "num_cases = len(frequencies) * len(functions)\n",
    "\n",
    "for f in functions:\n",
    "    for freq in frequencies:\n",
    "        dat = gen_function_data(f, freq, NSAMPLE//(num_cases))\n",
    "        output_dfs.append(dat)\n",
    "\n",
    "# Simple commands to generate data\n",
    "# sine_df = gen_function_data(np.sin, 0.1, NSAMPLE)\n",
    "# square_df = gen_function_data(scipy.signal.square, 0.1, NSAMPLE)\n",
    "# tri_df = gen_function_data((lambda t: scipy.signal.sawtooth(t, width=0.5)), 0.1, NSAMPLE)\n",
    "# noise_df = gen_noise(NSAMPLE)\n",
    "\n",
    "# for o in output_dfs:\n",
    "#     display(o.describe())\n",
    "        \n",
    "# for o in output_dfs:\n",
    "#     ax = o[:1000].plot(x='seconds', y='value', kind=\"line\", figsize=(15,4), legend=False)\n",
    "#     ax.set_xlabel(\"seconds\")\n",
    "#     ax.set_ylabel(\"position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Synth Sourced Data\n",
    "\n",
    "Generating some data sourced from regular functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save synthetic Data in a compressed numpy file.\n",
    "dataset_location = '../datasets/'\n",
    "dataset_filename = 'empi-synthetic-dataset.npz'\n",
    "log_arrays = [np.array(log_df[['dt', 'value']]) for log_df in output_dfs]\n",
    "\n",
    "## Generate some stats and convert to compressed formats.\n",
    "raw_perfs = []\n",
    "acc = 0\n",
    "time = 0\n",
    "interactions = 0\n",
    "for l in log_arrays:\n",
    "    acc += l.shape[0] * l.shape[1]\n",
    "    interactions += l.shape[0]\n",
    "    time += l.T[0].sum()\n",
    "    raw = l.astype('float32')  # dt, x_1, ... , x_n\n",
    "    raw_perfs.append(raw)\n",
    "\n",
    "print(\"total number of values:\", acc)\n",
    "print(\"total number of interactions:\", interactions)\n",
    "print(\"total time represented:\", time, \"seconds\")\n",
    "print(\"total number of perfs in raw array:\", len(raw_perfs))\n",
    "raw_perfs = np.array(raw_perfs)\n",
    "np.savez_compressed(dataset_location + dataset_filename, perfs=raw_perfs)\n",
    "print(\"done saving:\", dataset_location + dataset_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Noise Sourced Data\n",
    "\n",
    "Generating some data sourced from uniform noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save noise Data in a compressed numpy file.\n",
    "NSAMPLE = 75000 #150000\n",
    "dataset_location = '../datasets/'\n",
    "dataset_filename = 'empi-noise-dataset.npz'\n",
    "log_arrays = [np.array(gen_noise(NSAMPLE)[['dt', 'value']])]\n",
    "\n",
    "## Generate some stats and convert to compressed formats.\n",
    "raw_perfs = []\n",
    "acc = 0\n",
    "time = 0\n",
    "interactions = 0\n",
    "for l in log_arrays:\n",
    "    acc += l.shape[0] * l.shape[1]\n",
    "    interactions += l.shape[0]\n",
    "    time += l.T[0].sum()\n",
    "    raw = l.astype('float32')  # dt, x_1, ... , x_n\n",
    "    raw_perfs.append(raw)\n",
    "\n",
    "print(\"total number of values:\", acc)\n",
    "print(\"total number of interactions:\", interactions)\n",
    "print(\"total time represented:\", time, \"seconds\")\n",
    "print(\"total number of perfs in raw array:\", len(raw_perfs))\n",
    "raw_perfs = np.array(raw_perfs)\n",
    "np.savez_compressed(dataset_location + dataset_filename, perfs=raw_perfs)\n",
    "print(\"done saving:\", dataset_location + dataset_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic data:\n",
    "\n",
    "The idea is to generate some data that \"could\" have been human, but has a regular pattern. The time axis is sampled from a normal distribution with the same mean and S.D. as the human corpus. The value axis is generated by applying regular signal functions (e.g., sine, square, triangle) to this time axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_length=1000\n",
    "\n",
    "def plot_gen_data(data_df, name='unknown'):\n",
    "    ax = data_df[:300].plot(x='seconds', y='value', kind=\"line\", figsize=(6,4), legend=False)\n",
    "    ax.set_xlabel(\"seconds\")\n",
    "    ax.set_ylabel(\"position\")\n",
    "    ax.get_figure().savefig('../images/synth_data_output/'+name+'_data_output.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "    ax.get_figure().savefig('../images/synth_data_output/'+name+'_data_output.png', dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# Generate fake Sine movement\n",
    "sine_df = gen_function_data(np.sin, 0.1, small_data_length)\n",
    "display(sine_df.describe())\n",
    "plot_gen_data(sine_df, name='sine')\n",
    "\n",
    "# Generate fake Squarey Movement\n",
    "square_df = gen_function_data(scipy.signal.square, 0.1, small_data_length)\n",
    "display(square_df.describe())\n",
    "plot_gen_data(square_df, name='square')\n",
    "\n",
    "# Generate fake triangle-y Movement\n",
    "tri_df = gen_function_data(scipy.signal.sawtooth, 0.1, small_data_length)\n",
    "display(tri_df.describe())\n",
    "plot_gen_data(tri_df, name='tri')\n",
    "\n",
    "# Generate noise\n",
    "noise_df = gen_noise(small_data_length)\n",
    "display(noise_df.describe())\n",
    "plot_gen_data(noise_df, name='noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the generated data is ready for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train networks with the Synthetic data\n",
    "\n",
    "Training an MDN with these synthetic data sets.\n",
    "\n",
    "### Here are the corpora\n",
    "\n",
    "- square_corpus\n",
    "- tri_corpus\n",
    "- sine_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "units = 256\n",
    "mixes = 8\n",
    "layers = 1\n",
    "batch_s = 100\n",
    "n_steps = 120\n",
    "epochs = 1\n",
    " n x\n",
    "# Train\n",
    "net = sketch_mdn.MixtureRNN(mode = sketch_mdn.NET_MODE_TRAIN, \n",
    "                            n_hidden_units=units, \n",
    "                            n_mixtures=mixes, \n",
    "                            batch_size=batch_s, \n",
    "                            sequence_length=n_steps, \n",
    "                            layers=layers)\n",
    "loader = sketch_mdn.SequenceDataLoader(num_steps=(n_steps + 1), batch_size=batch_s, corpus=tri_corpus)\n",
    "losses = net.train(loader, epochs, saving=True)\n",
    "## Plot the losses.\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate some generated data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "units = 128\n",
    "mixes = 8\n",
    "layers = 3\n",
    "batch_s = 1\n",
    "n_steps = 1\n",
    "\n",
    "# Instantiate Running Network\n",
    "net = sketch_mdn.MixtureRNN(mode = sketch_mdn.NET_MODE_RUN, \n",
    "                            n_hidden_units=units, \n",
    "                            n_mixtures=mixes, \n",
    "                            batch_size=batch_s, \n",
    "                            sequence_length=n_steps, \n",
    "                            layers=layers)\n",
    "\n",
    "first_touch = np.array([(0.01 + (np.random.rand()-0.5)*0.005), np.random.rand()])\n",
    "print(\"Test Input:\",first_touch)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    perf = net.generate_performance(first_touch,2000,sess)\n",
    "print(\"Test Output:\")\n",
    "perf_df = pd.DataFrame({'dt':perf.T[0], 'value':perf.T[1]})\n",
    "perf_df['seconds'] = perf_df.dt.cumsum()\n",
    "\n",
    "print(perf_df.describe())\n",
    "\n",
    "ax = perf_df[:2000].plot(x='seconds', y='value', kind=\"line\", figsize=(15,4), legend=False, color='r')\n",
    "ax.set_xlabel(\"seconds\")\n",
    "ax.set_ylabel(\"position\")\n",
    "ax.set_ylim([-0.1,1.1])\n",
    "ax.get_figure().savefig('synthetic_net_output.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "ax.get_figure().savefig('synthetic_net_output.png', dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "units = 128\n",
    "mixes = 8\n",
    "layers = 3\n",
    "batch_s = 1\n",
    "n_steps = 1\n",
    "\n",
    "# Instantiate Running Network\n",
    "net = sketch_mdn.MixtureRNN(mode = sketch_mdn.NET_MODE_RUN, \n",
    "                            n_hidden_units=units, \n",
    "                            n_mixtures=mixes, \n",
    "                            batch_size=batch_s, \n",
    "                            sequence_length=n_steps, \n",
    "                            layers=layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.freeze_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
